Classification of Kaggle Movie Review Sentiment Analysis


The dataset is a corpus of Rotten Tomato movie reviews from a Kaggle competition. A group of crowd sourced individuals annotated all the subphrases of sentences with the sentiment labels: “negative”, “somewhat negative”, “neutral”, “somewhat positive”, “positive”. In this project I will train a Naïve Bayes classifier on various feature sets using cross-validation to obtain precision, recall and F-measures scores to determine the best set for the task. There are 156,060 phrases in corpus of which I will begin with a subset of 1000. I chose 1000 as this sample size because without knowing anything about the data I can assume a standard deviation of .5 is often a fair value to ensure the sample is representing the population. Therefore, this gives me approximately a 95% confidence interval and a 3% margin of error or 99% confidence and a 4% margin of error depending on how you want to look at it.  I believe this to be sufficient for the task at hand as it is a movie review classification and something needing higher accuracy such as heart attack detection.

To ensure the model doesn’t overfit I will be applying cross-validation of 10 folds to the Naïve Bayes classifier.  I will use precision, recall, and F1 scores to evaluate the differences in feature sets on the performance of the model. However, I will include an overall accuracy value, not cross-validated, just as a high-level view to base the inclusion of a confusion matrix in the beginning.  The confusion matrix will be viewing how the data is being skewed and how new bins can assist. The reason being that I do not intend to do a hard balancing of the data set.  As seen later in the analysis, I do complete some pre-procession to mitigate risks that could arise from this approach, and I will focus more on the micro averaging of the scores which is a weighted average of the labels.  '''
